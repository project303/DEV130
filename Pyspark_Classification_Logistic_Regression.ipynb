{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6pVeqt2mwKF"
      },
      "source": [
        "# Logistic Regression with PySpark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSpTdIXRorvF"
      },
      "source": [
        "## Download dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fu7apUDvoZb-"
      },
      "source": [
        "! wget -P dataset https://www.dropbox.com/s/d0t4lgw1gsq9t2r/pima-indians-diabetes.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcwuTt6to2EO"
      },
      "source": [
        "! ls -lah dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IdIRxtto6EP"
      },
      "source": [
        "! wc -l dataset/pima-indians-diabetes.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8A9KUYFo_bi"
      },
      "source": [
        "! head dataset/pima-indians-diabetes.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8z9WtAgS3zv9"
      },
      "source": [
        "Dataset description\n",
        "\n",
        "*   Pregnancies: Number of times pregnant\n",
        "*   Glucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
        "*   BloodPressure: Diastolic blood pressure (mm Hg)\n",
        "*   SkinThickness: Triceps skin fold thickness (mm)\n",
        "*   Insulin: 2-Hour serum insulin (mu U/ml)\n",
        "*   BMI: Body mass index (weight in kg/(height in m)^2)\n",
        "*   DiabetesPedigreeFunction: Diabetes pedigree function\n",
        "*   Age: Age (years)\n",
        "*   Outcome: Class variable --> 0 : no diabetes, 1: diabetes\n",
        "\n",
        "https://www.kaggle.com/uciml/pima-indians-diabetes-database\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sS1503_pPfH"
      },
      "source": [
        "## Apache Spark Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing openjdk-8-jdk"
      ],
      "metadata": {
        "id": "iO5ny7pDfe95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "metadata": {
        "id": "FpSrDtzzdJ74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing Apache Spark 2.4.7"
      ],
      "metadata": {
        "id": "z9-KkvBIf74r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://archive.apache.org/dist/spark/spark-2.4.7/spark-2.4.7-bin-hadoop2.7.tgz"
      ],
      "metadata": {
        "id": "uRreVDeWddZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tar xf spark-2.4.7-bin-hadoop2.7.tgz"
      ],
      "metadata": {
        "id": "JWHmjChGeoWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "EpV4c2q_evoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Spark Session"
      ],
      "metadata": {
        "id": "I_Vj8j3RgRZE"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXyyAxArtNIB"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.7-bin-hadoop2.7\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wbv3ffTctU2A"
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzqKqEqdtZu-"
      },
      "source": [
        "print(\"Spark version : \" + spark.version)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQYaGVtQteVC"
      },
      "source": [
        "import sys\n",
        "print(\"Python version : \" + sys.version)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "NjA_2nSJmwKR"
      },
      "source": [
        "#sc=spark.sparkContext\n",
        "#sqlContext=SQLContext(sc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkoobQWEmwKS"
      },
      "source": [
        "## Read File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1yT2Folu1rm"
      },
      "source": [
        "df_diabetes = spark.read.csv(path='dataset/pima-indians-diabetes.csv', \n",
        "                            sep=',', \n",
        "                            header = True, \n",
        "                            inferSchema = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZprYlWx0v-E4"
      },
      "source": [
        "df_diabetes.count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f57HhGW2wJAN"
      },
      "source": [
        "df_diabetes.show(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVzqZyMVwfqq"
      },
      "source": [
        "df_diabetes.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jg7k-ymdwaDo"
      },
      "source": [
        "## Statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oYU-Dkywapy"
      },
      "source": [
        "df_diabetes.describe().show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQBjXpNZwber"
      },
      "source": [
        "numeric_features = [t[0] for t in df_diabetes.dtypes if t[1] == 'int']\n",
        "df_diabetes.select(numeric_features).describe().toPandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74EJBZety4Fz"
      },
      "source": [
        "## Distribution of Target/Outcome"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDvR9m07wbUU"
      },
      "source": [
        "df_diabetes.groupby(\"Outcome\").count().show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lT7S7TN1DAK"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "sns.set_context('notebook')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkDzQnB-1KSK"
      },
      "source": [
        "data = df_diabetes.groupby(\"Outcome\").count().toPandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXCpSaB31SOD"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ha0azVOgy84w"
      },
      "source": [
        "sns.barplot(x='Outcome', y='count', data=data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQ-tTtBJmwKc"
      },
      "source": [
        "## Distribution of Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCAcq4Ic2ehO"
      },
      "source": [
        "df_diabetes.groupby(\"Pregnancies\").count().show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiuAD5tD3Ja3"
      },
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "sns.barplot(x='Pregnancies', y='count', data=df_diabetes.groupby(\"Pregnancies\").count().toPandas())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRTQHuUF5hGa"
      },
      "source": [
        "plt.figure(figsize=(25,8))\n",
        "sns.barplot(x='Glucose', y='count', data=df_diabetes.groupby(\"Glucose\").count().toPandas())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJDY-1bV89Sp"
      },
      "source": [
        "## Correlation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbR1_OBn880e"
      },
      "source": [
        "numeric_features = [t[0] for t in df_diabetes.dtypes if t[1] != 'string']\n",
        "numeric_features_df=df_diabetes.select(numeric_features)\n",
        "numeric_features_df.toPandas().head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dTPFkdM9ION"
      },
      "source": [
        "from pyspark.mllib.stat import Statistics\n",
        "\n",
        "col_names =numeric_features_df.columns\n",
        "features = numeric_features_df.rdd.map(lambda row: row[0:])\n",
        "corr_mat=Statistics.corr(features, method=\"pearson\")\n",
        "\n",
        "corr_mat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_POC84Jr9tUS"
      },
      "source": [
        "corr_df = pd.DataFrame(corr_mat)\n",
        "corr_df.index, corr_df.columns = col_names, col_names\n",
        "\n",
        "corr_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSsBS_RS9OeV"
      },
      "source": [
        "sns.heatmap(corr_df, \n",
        "        xticklabels=corr_df.columns,\n",
        "        yticklabels=corr_df.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WY7vvWz-1Yj"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tk_aTl8wBG77"
      },
      "source": [
        "## Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdLZC_wGAEk0"
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "inputCols = [\n",
        " 'Glucose',\n",
        " 'Insulin',\n",
        " 'BMI'\n",
        "]\n",
        "outputCol = \"features\"\n",
        "\n",
        "df_va = VectorAssembler(inputCols = inputCols, outputCol = outputCol)\n",
        "\n",
        "df_diabetes = df_va.transform(df_diabetes)\n",
        "#df.select(['features']).toPandas().head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jXCX7qTAEZi"
      },
      "source": [
        "df_diabetes.show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooaybeS4BKbY"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrN3GHFjBVQr"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KfhD8v1BKPx"
      },
      "source": [
        "train, test = df_diabetes.randomSplit([0.8, 0.2], seed = 2018)\n",
        "print(\"Training Dataset Count: \" + str(train.count()))\n",
        "print(\"Test Dataset Count: \" + str(test.count()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "747sTMf0CN9J"
      },
      "source": [
        "train.show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAxL4tBiBbrO"
      },
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(featuresCol = 'features', labelCol = 'Outcome', maxIter=5)\n",
        "lrModel = lr.fit(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-o0s5DPFZNa"
      },
      "source": [
        "trainingSummary = lrModel.summary\n",
        "roc = trainingSummary.roc.toPandas()\n",
        "plt.plot(roc['FPR'],roc['TPR'])\n",
        "plt.ylabel('False Positive Rate')\n",
        "plt.xlabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.show()\n",
        "print('Training set areaUnderROC: ' + str(trainingSummary.areaUnderROC))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKR_-7M5FhOs"
      },
      "source": [
        "## Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vGcl0RxFe2i"
      },
      "source": [
        "predictions = lrModel.transform(test)\n",
        "predictions.select('Outcome', 'features',  'rawPrediction', 'prediction', 'probability').toPandas().head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqX55hw0BoJg"
      },
      "source": [
        "accuracy = predictions.filter(predictions.Outcome == predictions.prediction).count() / float(predictions.count())\n",
        "print(\"Accuracy : \",accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IS5ejeMpDxC0"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "class_names=[1.0,0.0]\n",
        "import itertools\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('Outcome label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8An-mcwPDw7P"
      },
      "source": [
        "y_true = predictions.select(\"Outcome\")\n",
        "y_true = y_true.toPandas()\n",
        "\n",
        "y_pred = predictions.select(\"prediction\")\n",
        "y_pred = y_pred.toPandas()\n",
        "\n",
        "cnf_matrix = confusion_matrix(y_true, y_pred,labels=class_names)\n",
        "#cnf_matrix\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
        "                      title='Confusion matrix')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XMs1S0kDwvQ"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}